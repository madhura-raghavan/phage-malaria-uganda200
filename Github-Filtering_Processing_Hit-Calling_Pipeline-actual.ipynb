{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the dataset\n",
      "The number of total peptides is238068\n",
      "The number of samples in Round 2 768\n",
      "The number of samples remaining after filteering for <250,000 reads 734\n",
      "The samples with only 1 tech replicate are \n",
      "['Plate1_HC017', 'Plate2_GFAP', 'Plate2_HC035', 'Plate4_GFAP', 'Plate4_HC011', 'Plate4_HC044', 'Plate4_HC069', 'Plate4_HC070', 'Plate4_HC080', 'Plate4_HC084']\n",
      "The number of sample lefte after removing single replicates 724\n"
     ]
    }
   ],
   "source": [
    "## This pipeline generates the seroreactive peptide set of 9927 peptides used in all further analyses \n",
    "# There a few files created in the process that could be used for running any of these steps in between without having to start from the top\n",
    "## The final output file that has the set of 9927 seroreactive squences with information on whether it is seroreactive or not in a given sample (binary coding - 1/0) is 'HITS_Round2_Pfonly_250kfil_techclean_3zscorefil_5patientsfil.csv'\n",
    "\n",
    "\n",
    "### Filtering of data \n",
    "\n",
    "### Getting only Round2 reads \n",
    "### Discarding samples with <250,000 tooal reads\n",
    "### Discarding samples with only 1 tech replicate remaining after filtering by read count \n",
    "### Calculate reads per 500,000 - RP5K - this threshold chosen because most samplees have atleast 500,000 reads and so we can make use of that depth \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import numpy as np \n",
    "\n",
    "df_all = pd.read_csv(\"Gsnap_pairedend_alignment_raw_readcounts.csv\",header=0,index_col = 'peptide') ##peptide is the index\n",
    "df = df_all.filter(regex='Round2') ###Round2 \n",
    "total = df.sum(axis=0, numeric_only = True) ##get the total counts across all rows for each column \n",
    "\n",
    "### Choose the read depth normalization metric based on the read depth of the dataset\n",
    "## In the present dataset, most of the samples have at least 500,000 reads. \n",
    "## So reads per 500,000 has been used for this dataset \n",
    "\n",
    "df_rpk = df.div(0.00001*total,axis=1) ##calculate rpk (reads per 100,000) \n",
    "df_rpk = df_rpk.mul(5,axis=1)##calculate rpk (reads per 500,000)  \n",
    "\n",
    "print (\"Filtering the dataset\")\n",
    "print (\"The number of total peptides is\" + str(df.shape[0]))\n",
    "print (\"The number of samples in Round 2 \" + str(df.shape[1])) \n",
    "\n",
    "## Remove samples with less than 250,000 raw reads  \n",
    "\n",
    "df_rpk_countfil = df_rpk[df_rpk.columns.drop(total[total<250000].index)] \n",
    "\n",
    "print (\"The number of samples remaining after filteering for <250,000 reads \" + str(df_rpk_countfil.shape[1])) \n",
    "\n",
    "## identify samples where only 1 technical replicate is present \n",
    "\n",
    "col_name = []\n",
    "for col in df_rpk_countfil.columns:### loop through column names and collect the first two parts in a list and then count occurence freq in the list \n",
    "    name = '_'.join(col.split(\"_\")[0:2]) ## get the sample name that would be common in the other df as well\n",
    "    col_name.append(name) ## collect these names to the rerun list \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "freq = dict(Counter(col_name)) ### Get frequency of items in a list as a dictionary \n",
    "print (\"The samples with only 1 tech replicate are \")\n",
    "l = [k for k, v in freq.items() if v == 1] ### Get sammples who have only 1 replicate         \n",
    "print (l)\n",
    "### remove samples with only 1 replicate \n",
    "\n",
    "to_remove = '|'.join(l)\n",
    "df_rpk_clean = df_rpk_countfil.drop(df_rpk_countfil.filter(regex = to_remove,axis=1),axis=1)\n",
    "print (\"The number of sample lefte after removing single replicates \" + str(df_rpk_clean.shape[1]))### Saving the df_rpk_clean df to a csv file\n",
    "#df_rpk_clean.to_csv('Round2_RP5K_allpeptide_250kfilter_techclean.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Pf + Anopheles peptide is 230556\n"
     ]
    }
   ],
   "source": [
    "### Collecting Pf Only peptides \n",
    "\n",
    "\n",
    "### Dropping viral and human peptides \n",
    "\n",
    "df_PfOnly = df_rpk_clean.drop(list(df_rpk_clean.filter(regex = r'(virus|toxin|sapiens)',axis=0).index))\n",
    "\n",
    "print (\"The number of Pf + Anopheles peptide is \" + str(df_PfOnly.shape[0]))\n",
    "\n",
    "## Renormalizing RP5K values within the reduced dataset\n",
    "total_Pf = df_PfOnly.sum(axis=0, numeric_only = True) ##get the total of the remaining rows for each column \n",
    "df_PfOnly_rpk = df_PfOnly.div(0.000002*total_Pf,axis=1) ##calculate new rp5k for PF only peptides \n",
    "\n",
    "df_PfOnly_rpk.to_csv('Round2_RP5K_PfOnlypeptide_250kfilter_techclean.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peptides hits (>z-score of 3) in atleast 1 patient/healthy sample (both replicates) is 84363\n"
     ]
    }
   ],
   "source": [
    "### Calculating Z scores by Normal distribution for Pf only peptides and using a threshold of 3 and cmin of 5 to call hits \n",
    "### A peptide must be a hit in >75% of the replicates to be called a hit in a given sample \n",
    "\n",
    "\"\"\" detecting hits based on the healthy distribution\n",
    "1. copy the rpk file into a new one \n",
    "2. subtract all rpks for a given peptide with respective healthy mean\n",
    "3. Divide the above number with the healthy std dev for the peptide \n",
    "4. This number is the Z score \n",
    "5. If Z-score is >=3, call it a hit and give it a value of 1 in the new hit df. If not, give a value of 0. \n",
    "6. Also, store the Z-score in a new df. \n",
    "\"\"\"\n",
    "\n",
    "df_PfOnly_rpk = pd.read_csv('Round2_RP5K_PfOnlypeptide_250kfilter_techclean.csv',header = 0, index_col = 'peptide')\n",
    "\n",
    "df_PfOnly_rpk_Healthy = df_PfOnly_rpk.filter(regex = r'(HC|healthy|Healthy)',axis=1) ##collect the Healthy samples \n",
    "\n",
    "healthy_mean = df_PfOnly_rpk_Healthy.mean(axis=1,numeric_only=True) ##mean of healthy sampels for each peptide\n",
    "healthy_SD = df_PfOnly_rpk_Healthy.std(axis=1,numeric_only=True) ##sd of healthy sampels for each peptide\n",
    "healthy_SD.where(healthy_SD>1, 1, inplace=True) ###replace any SD <1 with 1 for ease in division later on. \n",
    "\n",
    "\n",
    "\n",
    "df_PfOnly_zscore = df_PfOnly_rpk.copy()\n",
    "\n",
    "df_PfOnly_zscore = df_PfOnly_zscore.sub(healthy_mean,axis=0)  ### sample rpk - mean rpk\n",
    "df_PfOnly_zscore = df_PfOnly_zscore.div(healthy_SD,axis=0) ### sample - mean divided by SD \n",
    "\n",
    "### Setting a threshold of Zscore of 3 for selecting as hits \n",
    "### look at technical replicates. Only if atleast 75% of the tech reps (3/4,4/5,5/6,2/2,3/3) call it a hit will it be considered a hit in that sample \n",
    "\n",
    "\n",
    "### Using PfOnly reads \n",
    "\n",
    "df_PfOnly_zscore3 = df_PfOnly_zscore.copy() ### copying zscores to a new df \n",
    "df_PfOnly_zscore3.where(df_PfOnly_zscore3>=3, 0, inplace= True)\n",
    "df_PfOnly_zscore3.where((df_PfOnly_zscore3<3), 1, inplace= True)\n",
    "\n",
    "\"\"\"\n",
    "1. Transpose the table so that column names are indices\n",
    "2. Split the index names and take only the common part before the Tech part \n",
    "3. Group technical replicates for each sample and take the mean \n",
    "4. If the mean is >= 0.75, call it a hit and give it a score of 1. If not, score is zero\n",
    "\"\"\"\n",
    "\n",
    "df_tech = df_PfOnly_zscore3.T ## transpose the matrix so that sample names are index names now \n",
    "df_tech['new_index'] = df_tech.index.to_series().str.split(\"_\").str[1:2].str.join(\"_\")\n",
    "rep = df_tech.groupby('new_index').mean()\n",
    "rep.where(rep>=0.75, 0, inplace= True)\n",
    "rep.where(rep<0.75, 1, inplace= True)  \n",
    "df_PfOnly_zscore3_hits = rep.T\n",
    "df_PfOnly_zscore3_hits = df_PfOnly_zscore3_hits.loc[df_PfOnly_zscore3_hits.sum(axis=1)!=0]  ### Only consider those hits where reps are both hits \n",
    "\n",
    "\n",
    "print(\"Number of peptides hits (>z-score of 3) in atleast 1 patient/healthy sample (both replicates) is \" + str(df_PfOnly_zscore3_hits.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of hits with 3zscore and 1 patient threshold is 63773\n",
      "The number of hits with 3zscore and 3 patient threshold is 20785\n",
      "The number of hits with 3zscore and 5 patient threshold is 9927\n",
      "The number of hits with 3zscore and 8 patient threshold is 5018\n"
     ]
    }
   ],
   "source": [
    "#### Setting 1, 3, 5, 8 patients as a threshold for selecting Malaria specific hits and boxing them in 3 categories. \n",
    "\n",
    "### 1. Collecting the number of healthys and patients that are HITS for each peptide\n",
    "df_aggregate_hit = df_PfOnly_zscore3_hits.copy()\n",
    "df_aggregate_Healthy = df_aggregate_hit.filter(regex = r'(HC|healthy|Healthy)',axis=1) ##collect the Healthy samples \n",
    "healthy_col = df_aggregate_Healthy.columns\n",
    "df_aggregate_Patient = df_aggregate_hit.drop(list(df_aggregate_hit.filter(regex = r'(HC|Healthy|gfap|Canary|GFAP|4F42|canary)',axis=1).columns),axis =1)\n",
    "patient_col = df_aggregate_Patient.columns\n",
    "\n",
    "healthyhitsum = df_aggregate_hit[healthy_col].sum(axis=1)\n",
    "patienthitsum = df_aggregate_hit[patient_col].sum(axis=1)\n",
    "\n",
    "hit = pd.concat([healthyhitsum,patienthitsum],axis=1)\n",
    "hit.columns = ['healthy_R2','patient_R2']\n",
    "\n",
    "### Calculate mean zscore of replicates for the hits \n",
    "z_tech = df_PfOnly_zscore.T ## transpose the matrix so that sample names are index names now \n",
    "z_tech['new_index'] = z_tech.index.to_series().str.split(\"_\").str[1:2].str.join(\"_\") ###combining data for the healthys from plates 3 and 4  \n",
    "z_mean = z_tech.groupby('new_index').mean()\n",
    "# z_SD = z_tech.groupby('new_index').std()\n",
    "\n",
    "patient_5 = hit[hit.patient_R2>4]\n",
    "\n",
    "df_PfOnly_zscore3_hits.loc[patient_5.index].to_csv('HITS_Round2_Pfonly_250kfil_techclean_3zscorefil_5patientsfil.csv')\n",
    "\n",
    "print (\"The number of hits with 3zscore and 5 patient threshold is \" + str(patient_5.shape[0]))\n",
    "\n",
    "z_mean.T.loc[patient_5.index].to_csv('HITS_meanZscore_Round2_Pfonly_250kfil_techclean_3zscorefil_5patientsfil.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
